{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sasaki/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sasaki/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sasaki/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sasaki/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sasaki/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sasaki/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "# First, transform the input into a 16x16 128-channels feature map\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "# Then, add a convolution layer\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Upsample to 32x32\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Few more conv layers\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Produce a 32x32 1-channel feature map\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/sasaki/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# One dropout layer - important trick!\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "# Classification layer\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "# To stabilize training, we use learning rate decay\n",
    "# and gradient clipping (by value) in the optimizer.\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set discriminator weights to non-trainable\n",
    "# (will only apply to the `gan` model)\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 29s 0us/step\n",
      "WARNING:tensorflow:From /home/sasaki/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasaki/.local/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 0: 0.6936629\n",
      "adversarial loss at step 0: 0.6764854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasaki/.local/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 100: 0.64719045\n",
      "adversarial loss at step 100: 0.716751\n",
      "discriminator loss at step 200: 0.6973787\n",
      "adversarial loss at step 200: 0.84038675\n",
      "discriminator loss at step 300: 0.7062826\n",
      "adversarial loss at step 300: 0.83691263\n",
      "discriminator loss at step 400: 0.70057344\n",
      "adversarial loss at step 400: 0.72769535\n",
      "discriminator loss at step 500: 0.7783117\n",
      "adversarial loss at step 500: 0.7308195\n",
      "discriminator loss at step 600: 0.70400333\n",
      "adversarial loss at step 600: 0.77470076\n",
      "discriminator loss at step 700: 0.69571054\n",
      "adversarial loss at step 700: 0.74152124\n",
      "discriminator loss at step 800: 0.6989714\n",
      "adversarial loss at step 800: 0.7724819\n",
      "discriminator loss at step 900: 0.6814144\n",
      "adversarial loss at step 900: 0.7547505\n",
      "discriminator loss at step 1000: 0.69005764\n",
      "adversarial loss at step 1000: 0.75111043\n",
      "discriminator loss at step 1100: 0.7001208\n",
      "adversarial loss at step 1100: 0.7223245\n",
      "discriminator loss at step 1200: 0.6936475\n",
      "adversarial loss at step 1200: 0.7693892\n",
      "discriminator loss at step 1300: 0.71342087\n",
      "adversarial loss at step 1300: 0.75826454\n",
      "discriminator loss at step 1400: 0.6915167\n",
      "adversarial loss at step 1400: 0.75536793\n",
      "discriminator loss at step 1500: 0.70014966\n",
      "adversarial loss at step 1500: 0.755814\n",
      "discriminator loss at step 1600: 0.6995028\n",
      "adversarial loss at step 1600: 1.1845992\n",
      "discriminator loss at step 1700: 0.731995\n",
      "adversarial loss at step 1700: 0.7682883\n",
      "discriminator loss at step 1800: 0.70855045\n",
      "adversarial loss at step 1800: 0.7122482\n",
      "discriminator loss at step 1900: 0.6985216\n",
      "adversarial loss at step 1900: 0.7553931\n",
      "discriminator loss at step 2000: 0.6916243\n",
      "adversarial loss at step 2000: 0.7716075\n",
      "discriminator loss at step 2100: 0.7100088\n",
      "adversarial loss at step 2100: 0.7515992\n",
      "discriminator loss at step 2200: 0.69962275\n",
      "adversarial loss at step 2200: 0.74420995\n",
      "discriminator loss at step 2300: 0.69161063\n",
      "adversarial loss at step 2300: 0.7466227\n",
      "discriminator loss at step 2400: 0.71207887\n",
      "adversarial loss at step 2400: 0.8084316\n",
      "discriminator loss at step 2500: 0.69039524\n",
      "adversarial loss at step 2500: 0.75301343\n",
      "discriminator loss at step 2600: 0.6854528\n",
      "adversarial loss at step 2600: 0.7316891\n",
      "discriminator loss at step 2700: 0.69200623\n",
      "adversarial loss at step 2700: 1.1079246\n",
      "discriminator loss at step 2800: 0.79453486\n",
      "adversarial loss at step 2800: 0.73506725\n",
      "discriminator loss at step 2900: 0.69643444\n",
      "adversarial loss at step 2900: 0.7934567\n",
      "discriminator loss at step 3000: 0.6893747\n",
      "adversarial loss at step 3000: 0.71048373\n",
      "discriminator loss at step 3100: 0.69925296\n",
      "adversarial loss at step 3100: 0.7013083\n",
      "discriminator loss at step 3200: 0.6932801\n",
      "adversarial loss at step 3200: 0.74852645\n",
      "discriminator loss at step 3300: 0.685558\n",
      "adversarial loss at step 3300: 0.7736224\n",
      "discriminator loss at step 3400: 0.689278\n",
      "adversarial loss at step 3400: 0.7929049\n",
      "discriminator loss at step 3500: 0.6971604\n",
      "adversarial loss at step 3500: 0.74908346\n",
      "discriminator loss at step 3600: 0.6905047\n",
      "adversarial loss at step 3600: 0.74291164\n",
      "discriminator loss at step 3700: 0.7020966\n",
      "adversarial loss at step 3700: 0.83091766\n",
      "discriminator loss at step 3800: 0.7688691\n",
      "adversarial loss at step 3800: 0.84076405\n",
      "discriminator loss at step 3900: 0.69935566\n",
      "adversarial loss at step 3900: 0.727502\n",
      "discriminator loss at step 4000: 0.67724407\n",
      "adversarial loss at step 4000: 0.7454901\n",
      "discriminator loss at step 4100: 0.68942803\n",
      "adversarial loss at step 4100: 0.70678866\n",
      "discriminator loss at step 4200: 0.6844212\n",
      "adversarial loss at step 4200: 1.7003514\n",
      "discriminator loss at step 4300: 0.68401736\n",
      "adversarial loss at step 4300: 0.73129576\n",
      "discriminator loss at step 4400: 0.69331944\n",
      "adversarial loss at step 4400: 0.72723866\n",
      "discriminator loss at step 4500: 0.705379\n",
      "adversarial loss at step 4500: 0.7328239\n",
      "discriminator loss at step 4600: 0.6892449\n",
      "adversarial loss at step 4600: 0.7272523\n",
      "discriminator loss at step 4700: 0.699694\n",
      "adversarial loss at step 4700: 0.78470355\n",
      "discriminator loss at step 4800: 0.6829051\n",
      "adversarial loss at step 4800: 0.76775295\n",
      "discriminator loss at step 4900: 0.70860994\n",
      "adversarial loss at step 4900: 0.76453906\n",
      "discriminator loss at step 5000: 0.65414846\n",
      "adversarial loss at step 5000: 1.3064896\n",
      "discriminator loss at step 5100: 0.6885891\n",
      "adversarial loss at step 5100: 0.73745763\n",
      "discriminator loss at step 5200: 0.7269855\n",
      "adversarial loss at step 5200: 0.7149676\n",
      "discriminator loss at step 5300: 0.6746529\n",
      "adversarial loss at step 5300: 0.75178695\n",
      "discriminator loss at step 5400: 0.7063934\n",
      "adversarial loss at step 5400: 0.71495897\n",
      "discriminator loss at step 5500: 0.69949234\n",
      "adversarial loss at step 5500: 0.70743644\n",
      "discriminator loss at step 5600: 0.6835247\n",
      "adversarial loss at step 5600: 0.75025207\n",
      "discriminator loss at step 5700: 0.7010904\n",
      "adversarial loss at step 5700: 0.77583396\n",
      "discriminator loss at step 5800: 0.7069362\n",
      "adversarial loss at step 5800: 0.7285715\n",
      "discriminator loss at step 5900: 0.70062846\n",
      "adversarial loss at step 5900: 0.7706451\n",
      "discriminator loss at step 6000: 0.6672248\n",
      "adversarial loss at step 6000: 0.6022613\n",
      "discriminator loss at step 6100: 0.69069976\n",
      "adversarial loss at step 6100: 0.70333576\n",
      "discriminator loss at step 6200: 0.6928314\n",
      "adversarial loss at step 6200: 0.89221704\n",
      "discriminator loss at step 6300: 0.7002574\n",
      "adversarial loss at step 6300: 0.77531207\n",
      "discriminator loss at step 6400: 0.69751704\n",
      "adversarial loss at step 6400: 0.8018691\n",
      "discriminator loss at step 6500: 0.68458843\n",
      "adversarial loss at step 6500: 0.75994414\n",
      "discriminator loss at step 6600: 0.70993376\n",
      "adversarial loss at step 6600: 1.2070563\n",
      "discriminator loss at step 6700: 0.6975991\n",
      "adversarial loss at step 6700: 0.82883185\n",
      "discriminator loss at step 6800: 0.69934434\n",
      "adversarial loss at step 6800: 0.8914796\n",
      "discriminator loss at step 6900: 0.6902531\n",
      "adversarial loss at step 6900: 0.77304614\n",
      "discriminator loss at step 7000: 0.66492546\n",
      "adversarial loss at step 7000: 0.7488755\n",
      "discriminator loss at step 7100: 0.7730329\n",
      "adversarial loss at step 7100: 1.0030771\n",
      "discriminator loss at step 7200: 0.68934065\n",
      "adversarial loss at step 7200: 0.7721584\n",
      "discriminator loss at step 7300: 0.6899981\n",
      "adversarial loss at step 7300: 0.7248394\n",
      "discriminator loss at step 7400: 0.68849325\n",
      "adversarial loss at step 7400: 0.7617954\n",
      "discriminator loss at step 7500: 0.6909461\n",
      "adversarial loss at step 7500: 0.74676085\n",
      "discriminator loss at step 7600: 0.68656254\n",
      "adversarial loss at step 7600: 0.7670247\n",
      "discriminator loss at step 7700: 0.7075666\n",
      "adversarial loss at step 7700: 0.81499326\n",
      "discriminator loss at step 7800: 0.67753994\n",
      "adversarial loss at step 7800: 0.74560595\n",
      "discriminator loss at step 7900: 0.69462776\n",
      "adversarial loss at step 7900: 0.82618904\n",
      "discriminator loss at step 8000: 0.6825732\n",
      "adversarial loss at step 8000: 0.7999567\n",
      "discriminator loss at step 8100: 0.9088093\n",
      "adversarial loss at step 8100: 0.6669046\n",
      "discriminator loss at step 8200: 0.7374659\n",
      "adversarial loss at step 8200: 0.7242824\n",
      "discriminator loss at step 8300: 0.6812312\n",
      "adversarial loss at step 8300: 0.86344755\n",
      "discriminator loss at step 8400: 0.69825596\n",
      "adversarial loss at step 8400: 0.79008305\n",
      "discriminator loss at step 8500: 0.6613592\n",
      "adversarial loss at step 8500: 0.77294123\n",
      "discriminator loss at step 8600: 0.6900791\n",
      "adversarial loss at step 8600: 0.7462162\n",
      "discriminator loss at step 8700: 0.680272\n",
      "adversarial loss at step 8700: 0.7430532\n",
      "discriminator loss at step 8800: 0.65788984\n",
      "adversarial loss at step 8800: 0.6498451\n",
      "discriminator loss at step 8900: 0.76626766\n",
      "adversarial loss at step 8900: 1.6226137\n",
      "discriminator loss at step 9000: 0.73453695\n",
      "adversarial loss at step 9000: 0.6726118\n",
      "discriminator loss at step 9100: 0.7182455\n",
      "adversarial loss at step 9100: 0.73884284\n",
      "discriminator loss at step 9200: 0.6910405\n",
      "adversarial loss at step 9200: 0.7801482\n",
      "discriminator loss at step 9300: 0.67780524\n",
      "adversarial loss at step 9300: 0.7864922\n",
      "discriminator loss at step 9400: 0.7195922\n",
      "adversarial loss at step 9400: 0.93233746\n",
      "discriminator loss at step 9500: 0.6813997\n",
      "adversarial loss at step 9500: 0.7804275\n",
      "discriminator loss at step 9600: 0.6872692\n",
      "adversarial loss at step 9600: 0.70653856\n",
      "discriminator loss at step 9700: 0.7137246\n",
      "adversarial loss at step 9700: 1.0437717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 9800: 0.6876296\n",
      "adversarial loss at step 9800: 0.728429\n",
      "discriminator loss at step 9900: 0.6855539\n",
      "adversarial loss at step 9900: 0.74867535\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Load CIFAR10 data\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Select frog images (class 6)\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = './gan_images/'\n",
    "\n",
    "# Start training loop\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    # Decode them to fake images\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "    # Combine them with real images\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "\n",
    "    # Assemble labels discriminating real from fake images\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    # Train the discriminator\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    # sample random points in the latent space\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    # Assemble labels that say \"all real images\"\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    # Train the generator (via the gan model,\n",
    "    # where the discriminator weights are frozen)\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "      start = 0\n",
    "\n",
    "    # Occasionally save / plot\n",
    "    if step % 100 == 0:\n",
    "        # Save model weights\n",
    "        gan.save_weights('gan.h5')\n",
    "\n",
    "        # Print metrics\n",
    "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
    "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
    "\n",
    "        # Save one generated image\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
    "\n",
    "        # Save one real image, for comparison\n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
